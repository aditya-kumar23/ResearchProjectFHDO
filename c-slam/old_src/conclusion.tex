\chapter{Conclusion and Future Works}
\label{ch:conclusion}

This research thesis set out to provide a controlled, implementation-grounded comparison of two representative backend paradigms for multi-agent collaborative SLAM. First, it introduces a unified and reproducible ROS~2-based evaluation framework that executes both architectures under a common dataset, factor representation, and KPI instrumentation. This testbed enables fair side-by-side comparisons across latency, accuracy, communication, and resource utilisation. Second, it delivers two concrete backend implementations that represent contrasting architectural choices: a centralised incremental backend that maintains a global factor graph and publishes global updates, and a decentralised DDF-style backend that performs per-agent optimisation and exchanges interface information peer-to-peer. Third, it proposes an impairment-aware experimentation methodology that models packet loss, delay, and bandwidth limitations and applies these consistently across architectures, thereby enabling a systematic assessment of robustness under degraded communication. Finally, the evaluation provides a quantitative characterisation of architectural trade-offs through an empirical analysis spanning baseline operation (3 robots), scalability conditions (4--5 robots), and impaired-network scenarios, reporting ATE/RPE, latency and convergence behaviour, bandwidth consumption, CPU load, and memory footprint.


Taken together, the baseline, scaling, and impairment evaluations provide clear guidance on when each backend is preferable. When global accuracy and predictable convergence dominate system requirements, the centralised backend is the more suitable choice in the evaluated configurations, particularly as team size grows, where DDF shows both accuracy degradation and the potential for latency inflation due to coordination overhead. When bandwidth is the primary constraint, the decentralised backend is strongly advantageous, consistently achieving large uplink reductions, avoiding downlink entirely, and remaining memory-efficient. Under degraded communication, both systems degrade, but DDF is more sensitive when peer-to-peer corrections are reduced. 

Although the presented comparison is intentionally controlled to ensure fairness and interpretability, several limitations remain. The evaluation relies on COSMO-Bench pre-computed factors, which abstracts away frontend-induced effects and therefore does not capture variability introduced by online data association, loop closure discovery dynamics, or keyframe selection policies. In addition, the study contrasts two representative architectural extremes, centralised versus decentralised rather than exploring the broader design spectrum that includes hierarchical, brokered, and opportunistically hybrid systems. The scaling analysis is limited to a maximum of five robots in the reported experiments, and larger teams, heterogeneous compute capabilities, or asymmetric sensing configurations may alter the observed trade-offs. Finally, network impairments are modelled and applied systematically to preserve fairness across architectures; however, real deployments may exhibit more complex dynamics such as mobility-driven link variability, interference, topology changes, and extended partitions that are not fully represented by the impairment models used here.

Building on these findings and limitations, several directions appear promising. One priority is the implementation and evaluation of hybrid and adaptive backends that interpolate between centralised and decentralised operation, for example through temporary brokers, cluster heads, or edge-offload policies that adjust as network conditions change. A second direction is to improve distributed optimisation by investigating interface scheduling, prioritised constraint exchange, and more robust distributed solvers, with the goal of reducing DDF sensitivity to missing peer updates and mitigating coordination overhead at larger team sizes. Third, reintroducing online frontends or comparing multiple frontend variants would enable an end-to-end evaluation of how backend architectural choices interact with real-time loop closure discovery, outlier handling, and sensor heterogeneity. Finally, moving from single-machine multi-process emulation to multi-host deployment across physical machines would provide a more faithful representation of timing, contention, and network effects that arise in realistic multi-robot systems.
