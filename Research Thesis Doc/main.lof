\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Bipartite factor-graph representation of SLAM: circular pose nodes $\mathbf {x}_t$, rectangular landmark nodes $\mathbf {l}_i$, and square factor nodes (black) encoding constraints through different edge types (odometry, landmark observations, loop closures, prior).\relax }}{6}{figure.caption.6}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Generic SLAM pipeline with frontend and backend. \relax }}{8}{figure.caption.7}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces C-SLAM architectures: centralised, decentralised, and hybrid/hierarchical.\relax }}{11}{figure.caption.8}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Sequence diagram depicting agent--central server interaction.\relax }}{33}{figure.caption.12}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Sequence diagram depicting decentralised agent interaction and interface exchange.\relax }}{35}{figure.caption.13}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Efficiency-normalised metric for the r3 baseline: CPU-seconds per optimisation step. Bars show mean over repeats ($R=5$); error bars denote 95\% CI across repeats, with individual repeats overlaid. Lower values indicate less compute time spent per solver update.\relax }}{45}{figure.caption.14}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Compact summary of the r3 baseline (Table~\ref {tab:eval_baseline_r3}): ATE RMSE and total traffic with uplink/downlink split. Bars show mean over repeats ($R=5$); error bars denote 95\% CI across repeats.\relax }}{46}{figure.caption.16}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Scalability trend in the baseline sweep (Table~\ref {tab:eval_baseline_scalability_condensed}): ATE RMSE and traffic vs.\ team size (r3--r5) for WiFi and ProRadio. Lines show mean over repeats ($R=5$); error bars denote 95\% CI across repeats.\relax }}{48}{figure.caption.18}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Pareto view of baseline trade-offs across team sizes (r3--r5): ATE RMSE vs.\ total traffic for each successful repeat. This visualisation complements Figure~\ref {fig:eval_scalability} by showing per-run dispersion and the accuracy--bandwidth frontier for each architecture.\relax }}{48}{figure.caption.19}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces Decentralised diagnostic: ATE mean vs.\ DDF termination time. The x-axis reports \(T_{\mathrm {stop}}^{(\mathrm {team})}\) (time from \texttt {input\_end} until all agents emit \texttt {ddf\_stop}, team statistic = max over robots). Error bars denote 95\% CI over repeats ($R=5$).\relax }}{49}{figure.caption.20}%
\contentsline {figure}{\numberline {6.6}{\ignorespaces QoS sensitivity (r3): summary of how ATE and traffic shift from the baseline profile (RV-20) under BT-TL-10 and BT-TL-50. Lines show mean over repeats ($R=5$); error bars denote 95\% CI across repeats. Failed configurations are marked.\relax }}{50}{figure.caption.22}%
\contentsline {figure}{\numberline {6.7}{\ignorespaces Normalised impairment sensitivity (slowdown vs.\ baseline) under uplink-only (publisher-impaired) degradations (Tables~\ref {tab:eval_impair_centralised} and~\ref {tab:eval_impair_decentralised}): centralised \(t_{\mathrm {global}}/t_{\mathrm {base}}\) and decentralised Iface p95$/t_{\mathrm {base}}$. Points show mean over repeats ($R=5$); error bars denote 95\% CI across repeats. Failed runs are marked.\relax }}{53}{figure.caption.25}%
\contentsline {figure}{\numberline {6.8}{\ignorespaces Robustness matrix summarising which configurations are supported (all repeats ok) vs.\ unsupported (at least one repeat fails) across the three studies: baseline, QoS, and impairments. Green \texttt {ok} indicates all repeats completed successfully; red \texttt {fail} indicates at least one repeat failed; grey \texttt {n/a} indicates a configuration not evaluated in this study (QoS is evaluated at r3 only; impairments at r3 and r5 only).\relax }}{54}{figure.caption.26}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Resource traces over time for the r3 baseline: centralised CPU/RSS of the server process vs.\ decentralised CPU/RSS aggregated across agents (sum over per-agent processes). Time is aligned to the start of each run. These traces support diagnosis of stability issues (e.g., monotonic RSS growth preceding agent crashes) and complement the aggregate means reported in Table~\ref {tab:eval_baseline_r3}.\relax }}{A4}{figure.caption.32}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces Absolute timing under impairments (supplementary): centralised \(t_{\mathrm {global}}\) and decentralised interface stabilisation latency across impairment conditions. This figure complements the normalised slowdown view in Figure~\ref {fig:eval_impairment_degradation}.\relax }}{A4}{figure.caption.33}%
\contentsfinish 
\contentsfinish 
